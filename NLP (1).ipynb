{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6b5c6f-c39e-47f1-8979-cf03b43057fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text:  Runners running.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences:\n",
      "['Runners running']\n",
      "\n",
      "Words:\n",
      "['Runners', 'running']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#tokenization\n",
    "import re\n",
    "\n",
    "text = input(\"Enter text: \")\n",
    "text=text.lower()\n",
    "sentences = re.split(r'[.!?]+', text)\n",
    "sentences = [s.strip() for s in sentences if s.strip()]\n",
    "words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "print(\"\\nSentences:\")\n",
    "print(sentences)\n",
    "print(\"\\nWords:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c302381-1d61-4b3d-ac38-9246867ba69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redoing -> do\n",
      "unwanted -> want\n",
      "caresses -> caress\n",
      "running -> runn\n",
      "cats -> cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#porter stemmer\n",
    "def simple_porter_stem(word):\n",
    "    word = word.lower()\n",
    "    # Example: remove common prefixes using startswith()\n",
    "    if word.startswith(\"re\"):\n",
    "        word = word[2:]\n",
    "    elif word.startswith(\"un\"):\n",
    "        word = word[2:]\n",
    "    # Remove plural endings\n",
    "    if word.endswith(\"sses\"):\n",
    "        word = word[:-2]\n",
    "    elif word.endswith(\"ies\"):\n",
    "        word = word[:-2]\n",
    "    elif word.endswith(\"s\") and not word.endswith(\"ss\"):\n",
    "        word = word[:-1]\n",
    "    # Remove past/continuous endings\n",
    "    elif word.endswith(\"ing\"):\n",
    "        word = word[:-3]\n",
    "    elif word.endswith(\"ed\"):\n",
    "        word = word[:-2]\n",
    "    return word\n",
    "\n",
    "# Example\n",
    "words = [\"redoing\", \"unwanted\", \"caresses\", \"running\", \"cats\"]\n",
    "for w in words:\n",
    "    print(w, \"->\", simple_porter_stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8219c05-b8ef-462c-b69f-b60c47a9380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow!', 'Is this working?', 'Yes it is.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sentence boundary\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "m=LogisticRegression().fit([[1],[0]],[1,0])\n",
    "t=\"Wow! Is this working? Yes it is.\".split()\n",
    "o=[t[0]]\n",
    "\n",
    "for i in range(1,len(t)):\n",
    "    if t[i-1][-1] in \".!?\" and m.predict([[t[i][0].isupper()]])[0]:\n",
    "        o.append(t[i])\n",
    "    else:\n",
    "        o[-1]+=\" \"+t[i]\n",
    "\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a236fae-034a-4da3-9551-6b1e0ec872f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 1 :\n",
      "AI is powerful\n",
      "Machine learning improves AI\n",
      "\n",
      "TOPIC 2 :\n",
      "Football is popular\n",
      "The match was exciting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#topic boundary\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "m=LogisticRegression().fit([[0],[1]],[0,1])\n",
    "s=[\"AI is powerful\",\"Machine learning improves AI\",\"Football is popular\",\"The match was exciting\"]\n",
    "\n",
    "t=1;print(\"TOPIC\",t,\":\");print(s[0])\n",
    "prev=1\n",
    "\n",
    "for i in range(1,len(s)):\n",
    "    o=len(set(s[i-1].split())&set(s[i].split()))>0\n",
    "    if prev and not o and m.predict([[1]])[0]:\n",
    "        t+=1;print(\"\\nTOPIC\",t,\":\")\n",
    "    print(s[i]);prev=o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee430387-1317-42cc-8e62-ea6df4a131e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S              \n",
      "      _______|___            \n",
      "     |           VP         \n",
      "     |        ___|___        \n",
      "     NP      |       NP     \n",
      "  ___|___    |    ___|___    \n",
      " DT      NN  V   DT      NN \n",
      " |       |   |   |       |   \n",
      "the     boy hit the     ball\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#phrase structure constituency\n",
    "\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.tree import Tree\n",
    "\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DT NN\n",
    "VP -> V NP\n",
    "DT -> 'the'\n",
    "NN -> 'boy' | 'ball'\n",
    "V -> 'hit'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "sentence = \"the boy hit the ball\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2a1e15-929f-4241-be23-5986c72047bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hit (boy the) (ball the))\n",
      "    hit     \n",
      "  ___|___    \n",
      "boy     ball\n",
      " |       |   \n",
      "the     the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dependency tree\n",
    "\n",
    "import nltk\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import ProjectiveDependencyParser\n",
    "\n",
    "# Define dependency grammar\n",
    "grammar = DependencyGrammar.fromstring(\"\"\"\n",
    "'hit' -> 'boy' | 'ball'\n",
    "'boy' -> 'the'\n",
    "'ball' -> 'the'\n",
    "\"\"\")\n",
    "\n",
    "# Create parser\n",
    "parser = ProjectiveDependencyParser(grammar)\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"the boy hit the ball\".split()\n",
    "\n",
    "# Parse and print tree\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f414f38-f5b3-47ad-b5d7-2bbdfd933608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK\t\tINPUT\t\tACTION\n",
      "['the'] \t ['boy', 'hit', 'the', 'ball'] \tSHIFT\n",
      "['the', 'boy'] \t ['hit', 'the', 'ball'] \tSHIFT\n",
      "['the', 'boy', 'hit'] \t ['the', 'ball'] \tSHIFT\n",
      "['the', 'boy', 'hit', 'the'] \t ['ball'] \tSHIFT\n",
      "['the', 'boy', 'hit', 'the', 'ball'] \t [] \tSHIFT\n",
      "['the', 'boy', 'hit', 'the', 'ball'] \t [] \tREDUCE\n",
      "\n",
      "             S              \n",
      "      _______|___            \n",
      "     |           VP         \n",
      "     |        ___|___        \n",
      "     NP      |       NP     \n",
      "  ___|___    |    ___|___    \n",
      " DT      NN  V   DT      NN \n",
      " |       |   |   |       |   \n",
      "the     boy hit the     ball\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shift reduce\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import ShiftReduceParser\n",
    "\n",
    "g = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DT NN\n",
    "VP -> V NP\n",
    "DT -> 'the'\n",
    "NN -> 'boy' | 'ball'\n",
    "V -> 'hit'\n",
    "\"\"\")\n",
    "\n",
    "p = ShiftReduceParser(g)\n",
    "s = \"the boy hit the ball\".split()\n",
    "\n",
    "print(\"STACK\\t\\tINPUT\\t\\tACTION\")\n",
    "stk = []\n",
    "inp = s[:]\n",
    "\n",
    "for w in s:\n",
    "    stk.append(w)\n",
    "    inp.pop(0)\n",
    "    print(stk, \"\\t\", inp, \"\\tSHIFT\")\n",
    "\n",
    "print(stk, \"\\t\", inp, \"\\tREDUCE\\n\")\n",
    "\n",
    "for t in p.parse(s):\n",
    "    t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae37062-7d68-482e-82a2-028d8d54cf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc977e91-c0fa-437d-afae-30a1615daa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
